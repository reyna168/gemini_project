import argparse
import asyncio
import os
from google import genai
from google.genai import types
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client



def parse_args():
    parser = argparse.ArgumentParser(description="é€é Gemini è‡ªå‹•å‘¼å«å·¥å…·ä¸¦ç”¢ç”Ÿçµæœ")
    parser.add_argument(
        "--required_tools",
        type=str,
        default="count_r,count_l,count_e",
        help="å¿…è¦ä½¿ç”¨çš„å·¥å…·åç¨±ï¼Œä½¿ç”¨é€—è™Ÿåˆ†éš”"
    )
    parser.add_argument(
        "--base_prompt",
        type=str,
        default="è«‹ä½¿ç”¨å·¥å…·è¨ˆç®—ä¸‹åˆ—ä¸‰å€‹å­—ï¼šã€Œroleã€ã€ã€Œretroreflectorã€èˆ‡ã€Œrewriteã€ä¸­åˆ†åˆ¥åŒ…å«å¹¾å€‹å­—æ¯ r, eã€‚",
        help="åŸå§‹æç¤ºèª"
    )
    return parser.parse_args()

GOOGLE_API_KEY = ""


client = genai.Client(api_key = GOOGLE_API_KEY)

server_params = StdioServerParameters(
    command="python",
    args=["mcpserver_2.py"]
)


async def ask_gemini(prompt, tools=None, temperature=0):
    return client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[{"role": "user", "parts": [{"text": prompt}]}],
        config=types.GenerateContentConfig(temperature=temperature, tools=tools),
    )


async def judge_if_answerable(base_prompt, tool_outputs):
    prompt = (
        f"åŸå§‹å•é¡Œï¼š{base_prompt}\n\n"
        f"ç›®å‰å¯ç”¨è³‡è¨Šï¼š\n{chr(10).join(tool_outputs)}\n\n"
        "è«‹ä½ åªå›ç­” 'å¯ä»¥å›ç­”' æˆ– 'ç„¡æ³•å›ç­”'ï¼Œä¸è¦æä¾›è§£é‡‹ã€‚"
    )
    response = await ask_gemini(prompt)
    return response.candidates[0].content.parts[0].text.strip()


async def ask_missing_info(base_prompt, tool_outputs):
    prompt = (
        f"åŸå§‹å•é¡Œï¼š{base_prompt}\n\n"
        f"ç›®å‰å¯ç”¨è³‡è¨Šï¼š\n{chr(10).join(tool_outputs)}\n\n"
        "ä½ ç„¡æ³•å®Œæ•´å›ç­”å•é¡Œï¼Œè«‹æŒ‡å‡ºé‚„éœ€è¦å“ªäº›è³‡è¨Šï¼ˆç°¡çŸ­åˆ—å‡ºï¼‰ã€‚"
    )
    response = await ask_gemini(prompt)
    return response.candidates[0].content.parts[0].text.strip()


async def run():
    
    args = parse_args()
    required_tools = set(t.strip() for t in args.required_tools.split(","))
    base_prompt = args.base_prompt

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            mcp_tools = await session.list_tools()

            tools = [
                {
                    "function_declarations": [
                        {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": {
                                k: v for k, v in tool.inputSchema.items()
                                if k not in ["additionalProperties", "$schema"]
                            },
                        }
                    ]
                } for tool in mcp_tools.tools
            ]

            print(f"\nğŸš€ åˆå§‹å•é¡Œ: {base_prompt}")
            initial_response = await ask_gemini(base_prompt, tools=tools)
            parts = initial_response.candidates[0].content.parts

            tool_outputs = []
            used_tools = set()

            for part in parts:
                if hasattr(part, "function_call") and part.function_call:
                    fc = part.function_call
                    print(f"ğŸ›  å‘¼å«å·¥å…·: {fc.name}, args: {fc.args}")
                    used_tools.add(fc.name)
                    result = await session.call_tool(fc.name, arguments=fc.args)
                    output_text = result.content[0].text
                    print(f"ğŸ“¦ å·¥å…·çµæœ: {output_text}")
                    tool_outputs.append(f"å·¥å…· `{fc.name}` å›å‚³ï¼š{output_text}")
                elif hasattr(part, "text"):
                    print("ğŸ§  Gemini è¼¸å‡ºï¼š", part.text)

            decision = await judge_if_answerable(base_prompt, tool_outputs)

            if "å¯ä»¥å›ç­”" in decision:
                print("\nâœ… å·²ç²è¶³å¤ è³‡è¨Šï¼Œæº–å‚™ç”¢å‡ºæœ€çµ‚å›ç­”")
                final_prompt = (
                    f"åŸå§‹å•é¡Œï¼š{base_prompt}\n\nä»¥ä¸‹æ˜¯ä½ å–å¾—çš„è³‡è¨Šï¼š\n{chr(10).join(tool_outputs)}\n\nè«‹æ ¹æ“šé€™äº›è³‡è¨Šï¼Œå›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚"
                )
                final_response = await ask_gemini(final_prompt)
                print("==========")
                print("ğŸ§¾ æœ€çµ‚å›ç­”ï¼š", final_response.candidates[0].content.parts[0].text)
            else:
                print("\nâš ï¸ è³‡è¨Šä¸è¶³ï¼Œç„¡æ³•å®Œæ•´å›ç­”ã€‚")
                missing_info = await ask_missing_info(base_prompt, tool_outputs)
                print("ğŸ” Gemini åˆ¤æ–·é‚„éœ€è¦ï¼š", missing_info)
                # æ­¤è™•å¯ä»¥æ“´å……å¯¦ä½œ: æ ¹æ“š missing_info å†æ±ºå®šå‘¼å«å“ªäº› toolï¼Œé€²è¡Œä¸‹ä¸€è¼ªå˜—è©¦


asyncio.run(run())